# Garak Backend Configuration
# Copy this file to .env and adjust values as needed

# =============================================================================
# Server Configuration
# =============================================================================
HOST=0.0.0.0
PORT=8888

# CORS Configuration (comma-separated origins)
# Use * for all origins (development only)
CORS_ORIGINS=*

# Logging Configuration
LOG_LEVEL=INFO

# =============================================================================
# Garak Configuration
# =============================================================================

# If garak is not in PATH, specify the full path (optional)
# GARAK_PATH=/path/to/garak

# Directory where garak stores scan reports
# Default (local): ~/.local/share/garak/garak_runs
# Default (container): /data/garak_reports
# GARAK_REPORTS_DIR=/path/to/garak_reports

# Garak service URL (container that runs garak CLI)
# Default: http://localhost:9090
# Docker: http://garak:9090
# GARAK_SERVICE_URL=http://localhost:9090

# =============================================================================
# Docker Configuration
# =============================================================================

# Host directory to mount for persistent scan reports
# This maps to /data/garak_reports inside the container
# GARAK_REPORTS_HOST_DIR=./garak_reports

# =============================================================================
# API Configuration
# =============================================================================
# MAX_CONCURRENT_SCANS=5

# =============================================================================
# LLM API Keys (required for respective providers)
# =============================================================================

# OpenAI
# OPENAI_API_KEY=sk-...

# Anthropic
# ANTHROPIC_API_KEY=sk-ant-...

# Mistral
# MISTRAL_API_KEY=...

# Cohere
# COHERE_API_KEY=...

# Hugging Face
# HF_INFERENCE_TOKEN=hf_...

# Replicate
# REPLICATE_API_TOKEN=r8_...

# NVIDIA NIM
# NIM_API_KEY=...

# =============================================================================
# Local Model Configuration
# =============================================================================

# Ollama host (for local models)
# Local: http://localhost:11434
# Docker: http://host.docker.internal:11434
# OLLAMA_HOST=http://localhost:11434
